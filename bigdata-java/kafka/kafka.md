#### kafka基础架构

![kafka](.\pic\kafka.jpg)

![kafka架构](.\pic\kafka架构.png)

**1）Producer** **：**消息生产者，就是向kafka broker发消息的客户端；

**2）Consumer** **：**消息消费者，向kafka broker取消息的客户端；

**3）Consumer Group** **（CG）：**消费者组，由多个consumer组成。**消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个消费者消费；消费者组之间互不影响。**所有的消费者都属于某个消费者组，即**消费者组是逻辑上的一个订阅者**。

**4）Broker** **：**一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。

**5）Topic** **：**可以理解为一个队列，**生产者和消费者面向的都是一个topic**；

**6）Partition：**为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，**一个topic可以分为多个partition**，每个partition是一个有序的队列；

**7）Replica：**副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个**leader**和若干个**follower**。

**8）leader：**每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。

**9）follower：**每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的follower。

#### 消息存储

主题（Topic）

kafka消息以topic为单位进行归类，逻辑概念

分区（Partition）

- Topic-Partition为一对多

- 分区在存储层面可看做是一个可追加的日志文件

- 消息在追加到分区时会分配一个特定的偏移量（offset）作为在此分区的唯一标示

- kafka通过offset保证消息在分区内的顺序性，但只保证分区有序而不保证主题有序

- 每条消息发送到broker前，会根据分区规则分配到具体的哪个分区

#### 容灾设计

###### 多副本机制(Replica)

- 一个分区会在多个副本中保存相同的消息

- 副本之间是一主多从关系

- leader副本负责读写操作，follower副本只负责同步消息（主动拉取）

- leader副本故障时，从follower副本重新选举新leader

![kafka容灾](.\pic\kafka容灾.png)

###### 同步状态

- 分区中所有副本统称为 AR（Assigned Replicas）
- 所有与leader副本保持一定程度同步的副本（包括leader）组成 ISR（In-Sync Replicas）
- 同步之后过多的副本组成 OSR（Out-of-Sync Replicas）

#### kafka生产者

##### 消息发送步骤

- 配置生产者客户端参数及创建相应的生产者实例，Properties和KafkaProducer
- 构建待发送的消息，ProducerRecord
- 发送消息，send()，flush()
- 关闭生产者实例：close()

##### 发送模式

- 发后即忘（fire-and-forget）：只管往kafka发送而不关心消息是否正确到达，不对发送结果进行判断处理；
- 同步（sync）：KafkaProducer.send()返回的是一个Future对象，使用Future.get()来阻塞获取任务发送的结果，来对发送结果进行相应的处理；
- 异步（async）：向send()返回的Future对象注册一个Callback回调函数，来实现异步的发送确认逻辑。

##### 原理分析

![生产者架构](.\pic\生产者架构.png)

- 主线程KafkaProducer创建消息，通过可能的拦截器、序列化器和分区器之后缓存到消息累加器（RecordAccumulatro）

- 消息在RecordAccumulator被包装成ProducerBatch，以便Sender线程可以批量发送，缓存的消息发送过慢时，send()方法会被阻塞或抛异常

- 缓存的大小通过buffer.memory配置，阻塞时间通过max.block.ms配置

- Kafka生产者客户端中，通过ByteBuffer实现消息内存的创建和释放，而RecordAccumulator内部有一个BufferPool用来实现ByteBuffer的复用

- Sender从RecordAccumulator中获取缓存的消息后，将ProducerBatch按Node分组，Node代表broker节点。也就是说sender只向具体broker节点发送消息，而不关注属于哪个分区，这里是应用逻辑层面到网络层面的转换

- Sender发往Kafka前，还会保存到InFlightRequests中，其主要作用是缓存已经发出去但还没收到相应的请求，也是以Node分组。

- 每个连接最大缓存未响应的请求数通过max.in.flight.requests.per.connection配置(默认5)

###### 元数据更新

- InFlightRequests可以获得leastLoadedNode，即所有Node中负载最小的。leastLoadedNode一般用于元数据请求、消费者组播协议等交互。

- 当客户端中没有需要使用的元数据信息或唱过metadata.max.age.ms没有更新元数据时，就会引起元数据更新操作。

#### kafka消费者

##### 消费者与消费者组

- 每个分区只能被一个消费组的一个消费者消费（消费者数大于分区数时，会有消费者分配不到分区而无法消费任何消息）

- 消费者并非逻辑上的概念，它是实际的应用实例，它可以是一个钱程，也可以是一个进程。

##### 多线程实现

- KafkaProducer是线程安全的，但KafkaConsumer是非线程安全的，acquire()方法可检测当前是否只有一个线程在操作，否则抛出异常

- 推荐使用单线程消费，而消息处理用多线程

  ![kafka多线程消费](.\pic\kafka多线程消费.png)

### 日志存储

#### 文件目录布局

- 一个分区副本对应一个日志(Log)，一个日志会分配成多个日志分段(LogSegment)，Log在物理上以文件夹形式存储，而LogSegment对应磁盘上的一个日志文件和2个索引文件及可能的其他文件。

- 向Log追加消息时是顺序写入的，只有最后一个LogSegment才能执行写入，称为activeSegment，满足一定条件时，需要创建新的activeSegment

- 每个日志及索引的文件名根据基准偏移量(BaseOffset)命名，表示当前LogSegment中第一条消息的offset

- broker配置了多个根目录时，会挑选分区数最少的根目录来创建主题

  ![日志存储](.\pic\日志存储.png)







## 生产者实践及原理剖析

### 消息分区机制原理剖析

#### 分区概念

Kafka有主题（Topic）的概念，它是承载真实数据的**逻辑容器**，而在主题之下还分为若干个分区，也就是说Kafka的消息组织方式实际上是三级结构：主题-分区-消息。**主题下的每一条消息只会保存在某一个分区中，而不会在多个分区中被保存多份**。官网上这张图非常清晰的展示了kafka的三级结构

#### 分区的作用

分区的作用就是提供负载均衡的能力，或者说对数据进行分区的主要原因，就是为了实现系统的高伸缩性（Scalability）。不同的分区能够被放置到不同节点的机器上，而数据的读写操作也都是针对分区这个粒度而进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。并且，我们还可以通过添加新的节点机器来增加整体系统的吞吐量。

值得注意的是，不同的分布式系统对分区的叫法也不尽相同。比如在 Kafka 中叫分区，在 MongoDB 和 Elasticsearch 中就叫分片 Shard，而在 HBase 中则叫 Region，在 Cassandra 中又被称作 vnode。从表面看起来它们实现原理可能不尽相同，但对底层分区（Partitioning）的整体思想却从未改变。

除了提供负载均衡这种最核心的功能之外，利用分区也可以实现其他一些业务级别的需求，比如实现业务级别的消息顺序的问题。

#### 分区策略

##### 轮询策略

也称 Round-robin 策略，即顺序分配

**轮询策略是 Kafka Java 生产者 API 默认提供的分区策略**。如果你未指定partitioner.class参数，那么你的生产者程序会按照轮询的方式在主题的所有分区间均匀地“码放”消息。

**轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。**

##### 随机策略

也称 Randomness 策略。所谓随机就是我们随意地将消息放置到任意一个分区上。

先计算出该主题总的分区数，然后随机地返回一个小于它的正整数。本质上看随机策略也是力求将数据均匀地打散到各个分区，但从实际表现来看，它要逊于轮询策略，所以**如果追求数据的均匀分布，还是使用轮询策略比较好**。事实上，随机策略是老版本生产者使用的分区策略，在新版本中已经改为轮询了。

##### 消息保存策略

Kafka 允许为每条消息定义消息键，简称为 Key。这个 Key 的作用非常大，它可以是一个有着明确业务含义的字符串，比如客户代码、部门编号或是业务 ID 等；也可以用来表征消息元数据。特别是在 Kafka 不支持时间戳的年代，在一些场景中，工程师们都是直接将消息创建时间封装进 Key 里面的。一旦消息被定义了 Key，那么你就可以保证同一个 Key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为按消息键保序策略，

### 消息压缩详解

#### 压缩方式

Kafka的消息层次分为两层：消息集合（messge set）以及消息（message）。一个消息集合中包含若干条日志项（record item），而日志项才是真正封装消息的地方。Kafka底层消息日志由一系列消息集合日志项组成。Kafka通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。

Kafka 共有两大类消息格式，社区分别称之为 V1 版本和 V2 版本。V2 版本是 Kafka 0.11.0.0 中正式引入的。

- 在 V2 版本中，消息的 CRC 校验工作就被移到了消息集合这一层。
- V1 版本中保存压缩消息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中，V2 版本的做法是对整个消息集合进行压缩。显然后者应该比前者有更好的压缩效果。
- 在相同条件下，不论是否启用压缩，V2 版本都比 V1 版本节省磁盘空间。当启用压缩时，这种节省空间的效果更加明显。

#### 何时压缩

##### 生产者端压缩

##### Broker端压缩

大部分情况下 Broker 从 Producer 端接收到消息后仅仅是原封不动地保存而不会对其进行任何修改，但这里的“大部分情况”也是要满足一定条件的。有两种例外情况就可能让 Broker 重新压缩消息。

- Broker端和Producer端采用了不同的压缩算法
- Broker端发生了消息格式转换（如过集群中同时保存多种版本的消息格式。为了兼容老版本，Broker会将消息转换为老版本格式，这对性能影响很大，而且会丧失Zero Copy的特性）

##### 何时解压缩

通常来说解压缩发生在消费者程序中，也就是说 Producer 发送压缩消息到 Broker 后，Broker 照单全收并原样保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。

那么现在问题来了，Consumer 怎么知道这些消息是用何种压缩算法压缩的呢？其实答案就在消息中。Kafka 会将启用了哪种压缩算法封装进消息集合中，这样当 Consumer 读取到消息集合时，它自然就知道了这些消息使用的是哪种压缩算法。如果用一句话总结一下压缩和解压缩，那么我希望你记住这句话：**Producer 端压缩、Broker 端保持、Consumer 端解压缩**。

### 无丢失消息配置实现

**Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证**。这里有两个核心要素：

#### 已提交的消息

当 Kafka 的若干个 Broker（根据配置策略，可以是一个，也可以是ALL） 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变为“已提交”消息了。

#### 有限度的持久化保证

其实就是说 Kafka 不丢消息是有前提条件的。假如你的消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。

### 幂等和事务

#### 消息交付可靠性保障定义

是指 Kafka 对 Producer 和 Consumer 要处理的消息提供什么样的承诺。常见的承诺有以下三种：

- 最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。
- 至少一次（at least once）：消息不会丢失，但有可能被重复发送。
- 精确一次（exactly once）：消息不会丢失，也不会被重复发送。

目前，**Kafka 默认提供的交付可靠性保障是第二种，即至少一次**。即只有 Broker 成功“提交”消息且 Producer 接到 Broker 的应答才会认为该消息成功发送。不过倘若消息成功“提交”，但 Broker 的应答没有成功发送回 Producer 端（比如网络出现瞬时抖动），那么 Producer 就无法确定消息是否真的提交成功了。因此，它只能选择重试，也就是再次发送相同的消息。这就是 Kafka 默认提供至少一次可靠性保障的原因，不过这会导致消息重复发送。

#### 事务

事务型 Producer 能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。另外，事务型 Producer 也不惧进程的重启。Producer 重启回来后，Kafka 依然保证它们发送消息的精确一次处理。

**当前Kafka的事务隔离级别主要是read commited**。

## 消费者实践及原理剖析

### 消费者组概念

Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。既然是一个组，那么组内必然可以有多个消费者或消费者实例（Consumer Instance），它们共享一个公共的 ID，这个 ID 被称为 Group ID。组内的所有消费者协调在一起来消费订阅主题（Subscribed Topics）的所有分区（Partition）。当然，每个分区只能由同一个消费者组内的一个 Consumer 实例来消费。

- Consumer Group 下可以有一个或多个 Consumer 实例。这里的实例可以是一个单独的进程，也可以是同一进程下的线程。在实际场景中，使用进程更为常见一些。
- Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group。
- Consumer Group 下所有实例订阅的主题的单个分区，只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费。
- 如果所有实例都属于同一个 Group，那么它实现的就是消息队列模型；如果所有实例分别属于不同的 Group，那么它实现的就是发布 / 订阅模型。

### 位移主题——consumer_offsets

#### 位移管理机制

##### 2.1.1 老版本

老版本 Consumer 的位移管理是依托于 Apache ZooKeeper 的，它会自动或手动地将位移数据提交到 ZooKeeper 中保存。当 Consumer 重启后，它能自动从 ZooKeeper 中读取位移数据，从而在上次消费截止的地方继续消费。这种设计使得 Kafka Broker 不需要保存位移数据，减少了 Broker 端需要持有的状态空间，因而有利于实现高伸缩性。

##### 2.1.2 新版本

新版本 Consumer 的位移管理机制其实也很简单，就是将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 __consumer_offsets 中。可以这么说，__consumer_offsets 的主要作用是保存 Kafka 消费者的位移信息。它要求这个提交过程不仅要实现高持久性，还要支持高频的写操作。显然，Kafka 的主题设计天然就满足这两个条件，因此，使用 Kafka 主题来保存位移这件事情，实际上就是一个水到渠成的想法了。

##### 2.1.3 位移主题的消息格式

位移主题的消息格式有3种

- 普通消息是一个 KV 对。Key 和 Value 分别表示消息的键值和消息体。Key 中保存 3 部分内容：<Group ID，主题名，分区号 >。
- 用于保存Consumer Group信息的消息。
- 用于删除Group过期位移甚至是删除Group的消息（它有个专属的名字：tombstone 消息，即墓碑消息，也称 delete mark）。

##### 2.2 创建位移主题

通常来说，**当Kafka集群中的第一个Consumer程序启动时，Kafka会自动创建位移主题**。

- Broker 端参数 offsets.topic.num.partitions决定分区数（默认50个分区）
- Broker 端参数 offsets.topic.replication.factor决定副本因子（默认值是3）

如果位移主题是 Kafka 自动创建的，那么该主题的分区数是 50，副本数是 3。

### 消费位移

Consumer 需要向 Kafka 汇报自己的位移数据，这个汇报过程被称为提交位移。因为 Consumer 能够同时消费多个分区的数据，所以位移的提交实际上是在分区粒度上进行的，即 Consumer 需要为分配给它的每个分区提交各自的位移数据。从用户的角度来说，位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。

##### 3.1 自动提交

Consumer 端有个参数叫 enable.auto.commit，如果值是 true，则 Consumer 在后台默默地为你定期提交位移，提交间隔由一个专属的参数 auto.commit.interval.ms 来控制。自动提交位移有一个显著的优点，就是省事，不用操心位移提交的事情，就能保证消息消费不会丢失。但这一点同时也是缺点。因为它太省事了，以至于丧失了很大的灵活性和可控性，完全没法把控 Consumer 端的位移管理。

##### 3.2 手动提交

即设置 enable.auto.commit = false。一旦设置了 false，作为 Consumer 应用开发的你就要承担起位移提交的责任。Kafka Consumer API 提供了位移提交的方法，如 consumer.commitSync 等。当调用这些方法时，Kafka 会向位移主题写入相应的消息。

##### 3.2.1 同步提交commitSync

KafkaConsumer#commitSync()方法会提交 KafkaConsumer#poll() 返回的最新位移。从名字上来看，它是一个同步操作，即该方法会一直等待，直到位移被成功提交才会返回。如果提交过程中出现异常，该方法会将异常信息抛出。

##### 3.2.2 异步提交commitAsync()

KafkaConsumer#commitAsync()从名字上来看它就不是同步的，而是一个异步操作。调用 commitAsync() 之后，它会立即返回，不会阻塞，因此不会影响 Consumer 应用的 TPS。由于它是异步的，Kafka 提供了回调函数（callback），供你实现提交之后的逻辑，比如记录日志或处理异常等。

commitAsync 是否能够替代 commitSync 呢？答案是不能。commitAsync 的问题在于，出现问题时它不会自动重试。因为它是异步操作，倘若提交失败后自动重试，那么它重试时提交的位移值可能早已经“过期”或不是最新值了。因此，异步提交的重试其实没有意义，所以 commitAsync 是不会重试的。

### 多线程消费者实践

Kafka Java Consumer采用的是双线程设计，即将用户主线程和心跳线程分开。

所谓用户主线程，就是你启动 Consumer 应用程序 main 方法的那个线程，而新引入的心跳线程（Heartbeat Thread）只负责定期给对应的 Broker 机器发送心跳请求，以标识消费者应用的存活性（liveness）。引入这个心跳线程还有一个目的，那就是期望它能将心跳频率与主线程调用 KafkaConsumer.poll 方法的频率分开，从而解耦真实的消息处理逻辑与消费者组成员存活性管理。

单线程Consumer的优点主要有：

- 能够较好的实现非阻塞式的消息获取
- 能够简化Consumer端的设计

#### 多个KafkaConsumer实例

消费者程序启动多个线程，每个线程维护专属的 KafkaConsumer 实例，负责完整的消息获取、消息处理流程

##### 2.1.1 方案优点

- 实现起来简单，因为它比较符合目前我们使用 Consumer API 的习惯。我们在写代码的时候，使用多个线程并在每个线程中创建专属的 KafkaConsumer 实例就可以了。
- 多个线程之间彼此没有任何交互，省去了很多保障线程安全方面的开销。
- 由于每个线程使用专属的 KafkaConsumer 实例来执行消息获取和消息处理逻辑，因此，Kafka 主题中的每个分区都能保证只被一个线程处理，这样就很容易实现分区内的消息消费顺序。这对在乎事件先后顺序的应用场景来说，是非常重要的优势。

##### 2.1.2 方案缺点

- 每个线程都维护自己的 KafkaConsumer 实例，必然会占用更多的系统资源，比如内存、TCP 连接等。在资源紧张的系统环境中，方案 1 的这个劣势会表现得更加明显。
- 这个方案能使用的线程数受限于 Consumer 订阅主题的总分区数。我们知道，在一个消费者组中，每个订阅分区都只能被组内的一个消费者实例所消费。假设一个消费者组订阅了 100 个分区，那么方案 1 最多只能扩展到 100 个线程，多余的线程无法分配到任何分区，只会白白消耗系统资源。当然了，这种扩展性方面的局限可以被多机架构所缓解。除了在一台机器上启用 100 个线程消费数据，我们也可以选择在 100 台机器上分别创建 1 个线程，效果是一样的。因此，如果你的机器资源很丰富，这个劣势就不足为虑了。
- 每个线程完整地执行消息获取和消息处理逻辑。一旦消息处理逻辑很重，造成消息处理速度慢，就很容易出现不必要的 Rebalance，从而引发整个消费者组的消费停滞。这个劣势你一定要注意。

#### 一个KafkaConsumer实例

消费者程序使用单或多线程获取消息，同时创建多个消费线程执行消息处理逻辑。获取消息的线程可以是一个，也可以是多个，每个线程维护专属的 KafkaConsumer 实例，处理消息则交由特定的线程池来做，从而实现消息获取与消息处理的真正解耦。

##### 2.2.1 方案优点

方案 2 将任务切分成了消息获取和消息处理两个部分，分别由不同的线程处理它们。比起方案 1，方案 2 的最大优势就在于它的高伸缩性，就是说我们可以独立地调节消息获取的线程数，以及消息处理的线程数，而不必考虑两者之间是否相互影响。如果你的消费获取速度慢，那么增加消费获取的线程数即可；如果是消息的处理速度慢，那么增加 Worker 线程池线程数即可。

##### 2.2.2 方案缺点

- 它的实现难度要比方案 1 大得多，毕竟它有两组线程，你需要分别管理它们。
- 因为该方案将消息获取和消息处理分开了，也就是说获取某条消息的线程不是处理该消息的线程，因此无法保证分区内的消费顺序。举个例子，比如在某个分区中，消息 1 在消息 2 之前被保存，那么 Consumer 获取消息的顺序必然是消息 1 在前，消息 2 在后，但是，后面的 Worker 线程却有可能先处理消息 2，再处理消息 1，这就破坏了消息在分区中的顺序。还是那句话，如果你在意 Kafka 中消息的先后顺序，方案 2 的这个劣势是致命的。
- 方案 2 引入了多组线程，使得整个消息消费链路被拉长，最终导致正确位移提交会变得异常困难，结果就是可能会出现消息的重复消费。如果你在意这一点，那么我不推荐你使用方案 2。

#### 总结

![优缺点](.\pic\优缺点.jpg)



参考：[kafka详解](https://blog.csdn.net/fedorafrog/article/details/103957908)



